sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release \
    software-properties-common \
    python3-pip \
    protobuf-compiler


pip3 install confluent-kafka protobuf requests

awk 'NF {sub(/\r/, ""); printf "%s\\\\n",$0;}' rsa_key.pem


# Create the properly formatted private key for JSON
FORMATTED_KEY=$(awk 'NF {sub(/\r/, ""); printf "%s\\\\n",$0;}' keys/rsa_key.pem)

sudo apt-get install -y jq

# Use jq to update the JSON config file
jq --arg key "$FORMATTED_KEY" '.config["snowflake.private.key"] = $key' config/snowflake-connector-config.json > config/snowflake-connector-config.json.new && mv config/snowflake-connector-config.json.new config/snowflake-connector-config.json

mkdir -p ./logs/zookeeper/data ./logs/zookeeper/log ./logs/kafka
chmod -R 777 ./logs


docker exec kafka kafka-topics --delete --topic topic1 --bootstrap-server kafka:29092

protoc --python_out=. --experimental_allow_proto3_optional proto/sample.proto

curl https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-linux-x86_64.zip >> protoc-3.19.zip
mkdir protoc-temp
unzip protoc-3.19.zip -d protoc-temp


python3 -m venv env
source env/bin/activate


mv /usr/bin/protoc /usr/bin/protoc-old
cp ./scripts/protoc-temp/bin/protoc /usr/bin/protoc


grep -v "KEY\|CERT" <cert>.pem | awk 'NF {sub(/\r/, ""); printf "%s",$0;}'


# Alternative deployment using docker exec
docker exec connect curl -X POST -H "Content-Type: application/json" \
  --data @/etc/kafka-connect/config/snowflake-connector-config.json \
  http://localhost:8083/connectors


docker exec -it schema-registry kafka-protobuf-console-consumer \
  --bootstrap-server kafka:29092 \
  --topic topic1 \
  --property schema.registry.url=http://schema-registry:8081 \
  --from-beginning

docker exec -it kafka kafka-run-class kafka.tools.GetOffsetShell \
  --bootstrap-server localhost:9092 \
  --topic topic1 \
  --time -1


echo '{"key": "1", "value": {"test": "message"}}' | sudo docker exec -i kafka kafka-console-producer --bootstrap-server localhost:9092 --topic topic1 --property "parse.key=true" --property "key.separator=:"

docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic topic1 --from-beginning


echo '{"key": {"id": "test-key"}, "value": {"id": 123, "name": "TEST_RECORD", "amount": 1234.56, "timestamp": 1709758842000, "is_active": true, "address": {"street": "123 Main St", "city": "New York", "state": "NY", "zip": "10001"}}}' > sample_message_with_key.json

cat sample_message_with_key.json | sudo docker exec -i schema-registry bash -c 'cat > /tmp/message.json && kafka-protobuf-console-producer --bootstrap-server kafka:29092 --topic topic1 --property schema.registry.url=http://schema-registry:8081 --property parse.key=true --property key.separator=: --property key.schema="syntax = \"proto3\"; package com.example; message Key { string id = 1; }" --property value.schema="syntax = \"proto3\"; package com.example; message SampleRecord { int32 id = 1; string name = 2; double amount = 3; int64 timestamp = 4; bool is_active = 5; message Address { string street = 1; string city = 2; string state = 3; string zip = 4; } Address address = 6; }" < /tmp/message.json'
